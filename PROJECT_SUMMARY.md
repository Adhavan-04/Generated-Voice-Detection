# üéØ AI Voice Detection Hackathon - Complete Project

## üì¶ What You Have

A complete, working AI voice detection system ready to deploy!

### Files Created:
1. **app.py** - Main API server (Flask-based)
2. **requirements.txt** - All dependencies
3. **Procfile** - Deployment configuration
4. **test_api.py** - API testing script
5. **test_interface.html** - Web-based testing interface
6. **app_ml.py** - ML-based version (optional upgrade)
7. **README.md** - Complete documentation
8. **DEPLOYMENT_GUIDE.md** - Deployment instructions
9. **STEP_BY_STEP_GUIDE.md** - Detailed walkthrough

---

## ‚ö° Quick Start (3 Steps)

### 1Ô∏è‚É£ Test Locally (5 minutes)

```bash
# Install dependencies
pip install -r requirements.txt

# Run the API
python app.py

# Test in browser
Open: http://localhost:5000
```

### 2Ô∏è‚É£ Deploy (10 minutes)

**Option A: Render.com (Recommended)**
1. Create GitHub account & upload files
2. Go to render.com and sign up
3. Create new Web Service from your GitHub repo
4. Set build command: `pip install -r requirements.txt`
5. Set start command: `gunicorn app:app`
6. Deploy! (takes 5-10 minutes)

**Option B: Railway.app**
1. Go to railway.app
2. "New Project" ‚Üí "Deploy from GitHub"
3. Select your repo
4. Done! Get your URL

### 3Ô∏è‚É£ Submit (2 minutes)

Submit to hackathon:
- **API URL**: `https://your-app.onrender.com/detect`
- **API Key**: `your_secure_api_key_here_123456`

---

## üîß How It Works

### Input Format
```json
{
  "audio": "BASE64_ENCODED_MP3_STRING"
}
```

### Output Format
```json
{
  "classification": "AI_GENERATED",
  "confidence": 0.87,
  "explanation": "AI-generated voice detected...",
  "language_support": ["Tamil", "English", "Hindi", "Malayalam", "Telugu"],
  "status": "success"
}
```

### Detection Method

The system analyzes:
- **Spectral Features**: Frequency distribution patterns
- **MFCCs**: Voice timbre characteristics  
- **Pitch**: Natural variation vs artificial consistency
- **Energy**: RMS and dynamic range
- **Temporal**: Zero-crossing rates and transitions
- **Harmonic**: Chroma features and harmonicity

AI voices typically show:
- ‚úì More uniform spectral patterns
- ‚úì Less pitch variation
- ‚úì Smoother transitions
- ‚úì Higher spectral flatness
- ‚úì Consistent energy levels

---

## üì± Testing Your API

### Method 1: Web Interface
1. Open `test_interface.html` in browser
2. Enter your API URL and key
3. Upload MP3 file
4. Click "Detect Voice"

### Method 2: Python Script
```bash
# Edit test_api.py with your URL and key
python test_api.py
```

### Method 3: cURL
```bash
curl -X POST https://your-api.onrender.com/detect \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer your_secure_api_key_here_123456" \
  -d '{"audio": "YOUR_BASE64_AUDIO"}'
```

### Method 4: Postman
1. POST request to your API
2. Add Authorization header
3. Send JSON with base64 audio

---

## üé§ Getting Test Audio

### Option 1: Record Yourself
- Use phone voice recorder
- Record 5-10 seconds of speech
- Export as MP3

### Option 2: Generate AI Voice
Free TTS services:
- **ElevenLabs** (elevenlabs.io) - Best quality
- **Google TTS** - Good for testing
- **Microsoft TTS** - Multiple languages
- **Amazon Polly** - Free tier available

### Option 3: Download Samples
- Use hackathon-provided sample
- Download from Google Drive link shared
- Test with both AI and human samples

---

## üöÄ Deployment Checklist

Before submitting:

- [ ] API deployed and accessible
- [ ] Health check works: `GET /health`
- [ ] Detection endpoint works: `POST /detect`
- [ ] Authentication works (API key)
- [ ] Tested with sample audio
- [ ] Response format is correct
- [ ] API is stable (test multiple times)
- [ ] API URL saved
- [ ] API key saved
- [ ] Handles errors gracefully

---

## üéØ API Endpoints

### 1. Detection (Main)
```
POST /detect
Header: Authorization: Bearer <API_KEY>
Body: {"audio": "base64_string"}
```

### 2. Health Check
```
GET /health
Response: {"status": "healthy", ...}
```

### 3. API Info
```
GET /
Response: API documentation
```

---

## üîë Important Notes

### API Key Security
- Change default key in app.py before deploying
- Use strong, random key
- Don't share publicly (except for hackathon submission)

### Free Tier Limitations
- **Render**: Sleeps after 15 min inactivity
- **Railway**: 500 hours/month
- **Vercel**: Serverless, may have cold starts
- First request after sleep: ~1 minute

### Audio Format
- Only MP3 supported currently
- Base64 encoding required
- File size: Recommend < 5MB
- Duration: Works best with 3-15 seconds

---

## üìä Expected Performance

### Current Implementation (Rule-Based)
- **Accuracy**: 60-75% (varies by voice quality)
- **Speed**: 2-5 seconds per request
- **Languages**: All 5 supported equally

### With ML Training (Optional)
- **Accuracy**: 80-90%+ (with good training data)
- **Speed**: 1-3 seconds per request
- **Requires**: 50+ samples per class

---

## üêõ Common Issues & Fixes

### "Module not found" Error
```bash
pip install -r requirements.txt --force-reinstall
```

### API Returns 401 (Unauthorized)
- Check API key matches in code and test
- Verify Authorization header format

### API Returns 400 (Bad Request)
- Ensure audio is base64 encoded
- Check JSON format
- Verify 'audio' field exists

### Deployment Fails
- Check Procfile exists
- Verify requirements.txt
- Review platform logs
- Ensure Python 3.9+

### Slow First Request
- Normal for free tier (wakes from sleep)
- Subsequent requests are fast
- Consider upgrade for production

---

## üéì Improvement Ideas (Post-Hackathon)

### 1. Machine Learning Model
- Collect training data (human + AI voices)
- Train RandomForest or XGBoost
- Use app_ml.py for ML implementation
- Expected: 80-90% accuracy

### 2. Deep Learning
- Use CNN or RNN for audio
- Pre-trained models: wav2vec, HuBERT
- Transfer learning on your data
- Expected: 90%+ accuracy

### 3. Additional Features
- Language detection
- Speaker identification
- Emotion analysis
- Accent detection

### 4. Better API
- Add rate limiting
- Implement caching
- Add batch processing
- WebSocket support for real-time

---

## üìö Learning Resources

### Audio Processing
- Librosa documentation: librosa.org
- Audio signal processing course (Coursera)
- Speech processing basics (YouTube)

### Machine Learning
- Scikit-learn audio classification
- PyTorch audio models
- TensorFlow audio tutorials

### API Development
- Flask documentation: flask.palletsprojects.com
- REST API best practices
- API security guidelines

---

## üí° Tips for Success

1. **Test Early**: Deploy and test before deadline
2. **Keep Logs**: Monitor your API during evaluation
3. **Have Backup**: Deploy on 2 platforms if possible
4. **Simple First**: Get basic version working, then improve
5. **Document**: Keep notes of your API URL, key, etc.

---

## üèÜ Hackathon Submission

### What to Submit:
1. **API Endpoint URL**
   ```
   https://your-app.onrender.com/detect
   ```

2. **API Key**
   ```
   your_secure_api_key_here_123456
   ```

3. **Optional Notes**
   - Mention supported audio format (MP3, Base64)
   - Note response includes confidence score
   - Mention multi-language support

### Evaluation Criteria:
- ‚úÖ API accessibility
- ‚úÖ Correct response format
- ‚úÖ Authentication works
- ‚úÖ Handles test audio correctly
- ‚úÖ Stability (multiple requests)
- ‚úÖ Accuracy of detection

---

## üéâ You're Ready!

### Final Checklist:
- [ ] API is deployed
- [ ] Tested with sample audio
- [ ] API key is secure
- [ ] URL is accessible
- [ ] Response format is correct
- [ ] Ready to submit

### Timeline:
- **Local Setup**: 30 minutes
- **GitHub Upload**: 15 minutes  
- **Deployment**: 20 minutes
- **Testing**: 15 minutes
- **Total**: ~1.5 hours

---

## üÜò Need Help?

### Quick Troubleshooting:
1. Check STEP_BY_STEP_GUIDE.md
2. Review DEPLOYMENT_GUIDE.md
3. Read error messages carefully
4. Test locally first
5. Check platform logs

### Resources:
- Render docs: docs.render.com
- Flask docs: flask.palletsprojects.com
- Librosa docs: librosa.org

---

## üéä Good Luck!

You have everything you need to:
1. ‚úÖ Deploy a working API
2. ‚úÖ Test it thoroughly
3. ‚úÖ Submit to hackathon
4. ‚úÖ Win! üèÜ

**Remember**: The goal is a working solution, not a perfect one. Get it deployed, test it, and submit it. You can always improve later!

---

**Project Created**: January 2026  
**For**: AI Voice Detection Hackathon  
**Status**: Ready to Deploy üöÄ
